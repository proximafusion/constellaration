{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "da625b4d",
            "metadata": {},
            "outputs": [],
            "source": [
                "%cd /constellaration\n",
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f40e87b4",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import matplotlib.pyplot as plt\n",
                "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
                "import numpy as np\n",
                "from constellaration import forward_model, problems\n",
                "\n",
                "from sklearn import decomposition, mixture, calibration\n",
                "\n",
                "from constellaration.generative_model import bootstrap_dataset\n",
                "\n",
                "from constellaration.generative_model import optimize_with_mcmc\n",
                "import seaborn as sns\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "07acd07b",
            "metadata": {},
            "source": [
                "This file demonstrates the generative model approach for simple-to-build QI problem. \n",
                "\n",
                "### 1. Load data from HuggingFace and do PCA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "09dcd504",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "DATASET_MAX_TOROIDAL_MODE = 4\n",
                "MAX_POLOIDAL_MODE = 4\n",
                "MAX_TOROIDAL_MODE = 4\n",
                "N_FIELD_PERIODS = 3\n",
                "SEED = 24\n",
                "dframe = bootstrap_dataset.load_source_datasets_with_no_errors()\n",
                "dframe = dframe[dframe[\"boundary.n_field_periods\"] == N_FIELD_PERIODS]\n",
                "dframe.head()\n",
                "# dframe = bootstrap_dataset._unflatten_metrics_and_concatenate(dframe)\n",
                "dframe = bootstrap_dataset._unserialize_surface(dframe)\n",
                "dframe = bootstrap_dataset._augment_dataset(dframe)\n",
                "print(f\"Dataset size: {dframe.shape[0]}\")\n",
                "\n",
                "problem = problems.SimpleToBuildQIStellarator()\n",
                "dframe.columns = [c.replace(\"metrics.\", \"\") if c != \"metrics.id\" \n",
                "                  else c for c in dframe.columns]\n",
                "dframe\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a50ef22a",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "problem = problems.SimpleToBuildQIStellarator()\n",
                "# Relax problem constraints\n",
                "relaxation_factor = 0.33\n",
                "#problem._aspect_ratio_upper_bound = 10.0 + 10.0 * relaxation_factor\n",
                "problem._edge_rotational_transform_over_n_field_periods_lower_bound =0.25 - 0.25 * relaxation_factor # noqa: E501\n",
                "problem._log10_qi_upper_bound = -4.0 + 4.0 * relaxation_factor\n",
                "problem._edge_magnetic_mirror_ratio_upper_bound = 0.2 + 0.2 * relaxation_factor\n",
                "problem._max_elongation_upper_bound = 5.0 + 5.0 * relaxation_factor\n",
                "\n",
                "X = bootstrap_dataset._to_X(\n",
                "    dframe=dframe,\n",
                "    max_poloidal_mode=MAX_POLOIDAL_MODE,\n",
                "    max_toroidal_mode=MAX_TOROIDAL_MODE,\n",
                ")\n",
                "Y_constraints = bootstrap_dataset._to_Y_constraints(\n",
                "    dframe=dframe,\n",
                "    problem=problem,\n",
                ")\n",
                "Y_objective = bootstrap_dataset._to_Y_objective(\n",
                "    dframe=dframe,\n",
                "    problem=problem,\n",
                ")\n",
                "n_feasible_candidates_in_the_data = np.sum(np.all(Y_constraints <= 0, axis=1))\n",
                "print(f\"Feasible candidates in the data: {n_feasible_candidates_in_the_data}\")\n",
                " # 1. PCA reduction\n",
                "pca = decomposition.PCA(n_components=0.9998, whiten=True)\n",
                "Z = pca.fit_transform(X)\n",
                "print(f\"Reduced to {Z.shape[1]} dimensions.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d8119827",
            "metadata": {},
            "source": [
                "### 2. Train GMM and random forest classifiers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3af8a902",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def get_classifier_regressor_GMM(\n",
                "    X: np.ndarray,\n",
                "    Y_cons: np.ndarray,\n",
                "    pca_explained_variance: float,\n",
                "    n_estimators: int,\n",
                "    seed: int,\n",
                ") -> np.ndarray:\n",
                "    n_feasible_candidates_in_the_data = np.sum(np.all(Y_cons <= 0, axis=1))\n",
                "    print(f\"Feasible candidates in the data: {n_feasible_candidates_in_the_data}\")\n",
                "\n",
                "    # 1. PCA reduction\n",
                "    pca = decomposition.PCA(n_components=pca_explained_variance, whiten=True)\n",
                "    Z = pca.fit_transform(X)\n",
                "    print(f\"Reduced to {Z.shape[1]} dimensions.\")\n",
                "\n",
                "   # 2) Train a classifier per constraint\n",
                "    constraint_classifiers: list[calibration.CalibratedClassifierCV] = []\n",
                "    for j in range(Y_cons.shape[1]):\n",
                "        y_bin = (Y_cons[:, j] <= 0).astype(int)\n",
                "        print(y_bin)\n",
                "        print(f\"Constraint {j}: {np.sum(y_bin)} feasible candidates\")\n",
                "        classifier = bootstrap_dataset._fit_calibrated_classifier(\n",
                "            X=Z,\n",
                "            y=y_bin,\n",
                "            random_state=seed,\n",
                "            n_estimators=n_estimators,\n",
                "        )\n",
                "        constraint_classifiers.append(classifier)\n",
                "        # Uncommet for debugging\n",
                "        calibration.CalibrationDisplay.from_estimator(\n",
                "            estimator=classifier,\n",
                "            X=Z,\n",
                "            y=y_bin,\n",
                "            n_bins=10,\n",
                "        )\n",
                "        plt.show()\n",
                "\n",
                "    probabilities = np.vstack(\n",
                "        [clf.predict_proba(X=Z)[:, 1] for clf in constraint_classifiers]\n",
                "    )\n",
                "    print(f\"Probabilities: {probabilities}\")\n",
                "    is_feasible = np.all(probabilities >= 0.8, axis=0)\n",
                "    print(f\"Number of samples used to fit GMM: {len(np.where(is_feasible)[0])}\")\n",
                "\n",
                "    # 3. Initialize GMM on PCA space\n",
                "    #gmm_n_components = bootstrap_dataset._n_components_that_minimizes_bic(Z, seed=seed)\n",
                "    gmm_n_components = 24\n",
                "    gmm = mixture.GaussianMixture(n_components=gmm_n_components, random_state=seed)\n",
                "    gmm.fit(Z[is_feasible])\n",
                "    #gmm.fit(Z)\n",
                "    print(f\"Fitted GMM with {gmm_n_components} components.\")\n",
                "\n",
                "    return gmm, pca, constraint_classifiers\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4df3254c",
            "metadata": {},
            "outputs": [],
            "source": [
                "gmm, pca, constraint_classifiers = get_classifier_regressor_GMM(\n",
                "        X=X,\n",
                "        Y_cons=Y_constraints,\n",
                "        pca_explained_variance=0.9998,\n",
                "        n_estimators=200,#100,\n",
                "        seed=SEED,\n",
                "    )\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "13817163",
            "metadata": {},
            "source": [
                "### 3. MCMC\n",
                "Take the GMM as a prior, with a \"quasi likelihood\" to maximize the probability of feasible domain, obtain a posterior with MCMC. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "64feee80",
            "metadata": {},
            "outputs": [],
            "source": [
                "def log_prior(x):\n",
                "    \"\"\"Log prior for the GMM parameters.\"\"\"\n",
                "    #atleast 2d\n",
                "    if x.ndim == 1:\n",
                "        x = x.reshape(1, -1)\n",
                "    return gmm.score_samples(x)\n",
                "def quasi_log_likelihood(x):\n",
                "    \"\"\"Log likelihood for the GMM parameters.\"\"\"\n",
                "    if x.ndim == 1:\n",
                "        x = x.reshape(1, -1)\n",
                "    cons =[]\n",
                "    for i,clf in enumerate(constraint_classifiers):\n",
                "        p = clf.predict(X=x)\n",
                "        cons.append(np.log(p + 1e-10))\n",
                "    cons = np.array(cons)\n",
                "    #cons = np.prod(cons, axis=0)\n",
                "    cons = np.sum(cons, axis=0)\n",
                "    # sum over the logp for three constraints\n",
                "    return cons\n",
                "def forward_(x): #noqa\n",
                "    \"\"\"Wrapper for the sphere function.\"\"\"\n",
                "    return None, None\n",
                "history = {\"x\": [], \"logp\": []}  \n",
                "def callback_print(state):\n",
                "    \"\"\"Callback function to save intermediate results.\"\"\"\n",
                "    # one can aslo save pickle files, or log to wandb.\n",
                "    history[\"x\"].append(state['current_sample'])\n",
                "    history[\"logp\"].append(state['logp'])\n",
                "    if state[\"iteration\"] % 100 == 0:\n",
                "        print(f\"Iteration: {state['iteration']}, logp: {state['logp']}\")\n",
                "probabilities = np.vstack(\n",
                "        [clf.predict_proba(X=Z)[:, 1] for clf in constraint_classifiers]\n",
                "    )\n",
                "is_feasible = np.all(probabilities >= 0.995, axis=0)\n",
                "\n",
                "Z[is_feasible].shape\n",
                "# Run the optimization with mcmc\n",
                "settings = optimize_with_mcmc.OptimizeWithMcmcSettings(\n",
                "    num_samples=4000,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3557d6a0",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "initial_guess = Z[is_feasible][0, :].reshape(-1)\n",
                "initial_guess = initial_guess + initial_guess * 0.1 * np.random.randn(*initial_guess.shape) #noqa\n",
                "mcmc_samples = optimize_with_mcmc.optimize_with_mcmc(\n",
                "    function=forward_,\n",
                "    x0=initial_guess,\n",
                "    callback=callback_print,\n",
                "    settings=settings,\n",
                "    prior=log_prior,\n",
                "    likelihood=quasi_log_likelihood,\n",
                ")\n",
                "\n",
                "plt.plot(history[\"logp\"][1000:])\n",
                "plt.xlabel(\"Iteration\")\n",
                "plt.ylabel(\"Log probability\")\n",
                "plt.grid()\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6eaf172b",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# randombly pick points from last 4000 points from mcmc_samples\n",
                "feasible_points = mcmc_samples[-4000:][np.random.choice(mcmc_samples[-4000:].shape[0], size=50, replace=False)] #noqa\n",
                "metrics_list = []\n",
                "x_feasible =pca.inverse_transform(feasible_points)\n",
                "for x_hat in x_feasible[-40:,:]:\n",
                "#for x_hat in pca.inverse_transform(Z[is_feasible][8:10,:]):\n",
                "    surface = bootstrap_dataset._x_to_surface(x_hat,\n",
                "                                          max_poloidal_mode=MAX_POLOIDAL_MODE,\n",
                "                                          max_toroidal_mode=MAX_TOROIDAL_MODE,\n",
                "                                          n_field_periods=N_FIELD_PERIODS,)\n",
                "    try:\n",
                "        metrics = forward_model.forward_model(\n",
                "            boundary=surface,\n",
                "            settings=forward_model.ConstellarationSettings()\n",
                "        )[0]\n",
                "        metrics_list.append(metrics)\n",
                "        print(f\"Max elongation: {metrics.max_elongation}\")\n",
                "    except Exception as _:\n",
                "        print(\"Error in forward model\")\n",
                "        metrics_list.append(np.nan)\n",
                "        continue\n",
                "for metrics in metrics_list:\n",
                "    #metrics.edge_rotational_transform_over_n_field_periods*=-1\n",
                "    # take abs value\n",
                "    metrics.edge_rotational_transform_over_n_field_periods = np.abs(metrics.edge_rotational_transform_over_n_field_periods) #noqa: E501\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "feac04fd",
            "metadata": {},
            "source": [
                "### 5. Compare with VMEC++ and plot results\n",
                "Might not match with the paper figure, as the seed would have changed. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0dd94dba",
            "metadata": {},
            "outputs": [],
            "source": [
                "# get feasible points in Z space in the dataset\n",
                "idx_feasible= np.where(np.all(Y_constraints <= 0, axis=1))[0]\n",
                "Z_feasible = Z[idx_feasible]\n",
                "\n",
                "# Extract green points (where all constraints are satisfied)\n",
                "c = np.all([\n",
                "    (clf.predict(X=mcmc_samples) == 1) \n",
                "    & (clf.predict_proba(X=mcmc_samples)[:, 1] > 0.95)\n",
                "    for clf in constraint_classifiers\n",
                "], axis=0)\n",
                "\n",
                "green_points = mcmc_samples[c]\n",
                "\n",
                "# Create a KDE plot for the green points\n",
                "fig, ax = plt.subplots()\n",
                "sns.kdeplot(\n",
                "    x=green_points[:, 0],\n",
                "    y=green_points[:, 1],\n",
                "    fill=True,\n",
                "    cmap=\"Greens\",\n",
                "    ax=ax,\n",
                "    alpha=0.6,\n",
                ")\n",
                "ax.set_xlabel(\"PC1\")\n",
                "ax.set_ylabel(\"PC2\")\n",
                "\n",
                "# Add the scatter plot on top of the KDE plot\n",
                "ax.scatter(\n",
                "    mcmc_samples[:, 0],\n",
                "    mcmc_samples[:, 1],\n",
                "    c=np.where(c, \"green\", \"red\"),\n",
                "    s=1,\n",
                "    label=\"MCMC Samples\",\n",
                ")\n",
                "\n",
                "# Add green crosses for VMEC points\n",
                "vmec_feasible = np.array([problem.is_feasible(metric) for metric in metrics_list])\n",
                "# vmec_feasible = []\n",
                "# for mm in metrics_list:\n",
                "#     if isinstance(mm, numbers.Number) and np.isnan(mm):\n",
                "#         vmec_feasible.append(False)\n",
                "#     else:\n",
                "#         vmec_feasible.append(problem.is_feasible(mm))\n",
                "vmec_feasible = np.array(vmec_feasible)\n",
                "ax.scatter(\n",
                "    feasible_points[-40:, 0],\n",
                "    feasible_points[-40:, 1],\n",
                "    c=np.where(vmec_feasible, \"green\", \"red\"),\n",
                "    marker=\"x\",\n",
                "    s=60,\n",
                "    label=\"VMEC\",\n",
                "    linewidths=0.7,\n",
                ")\n",
                "\n",
                "# Add feasible points from the dataset\n",
                "ax.scatter(\n",
                "    Z_feasible[:, 0],\n",
                "    Z_feasible[:, 1],\n",
                "    c=\"blue\",\n",
                "    marker=\"+\",\n",
                "    s=30,\n",
                "    label=\"Feasible Points in Dataset\",\n",
                "    linewidths=0.7,\n",
                ")\n",
                "\n",
                "#Set axis limits for the main plot. set limits based on the data.\n",
                "ax.set_xlim(0.6, 1.2)\n",
                "ax.set_ylim(0.5, 2.0)\n",
                "\n",
                "# Add an inset plot\n",
                "inset_ax = inset_axes(ax, width=\"55%\", height=\"55%\", loc=\"upper right\")\n",
                "sns.kdeplot(\n",
                "    x=green_points[:, 0],\n",
                "    y=green_points[:, 1],\n",
                "    fill=True,\n",
                "    cmap=\"Greens\",\n",
                "    ax=inset_ax,\n",
                "    alpha=0.6,\n",
                ")\n",
                "inset_ax.scatter(\n",
                "    mcmc_samples[:, 0],\n",
                "    mcmc_samples[:, 1],\n",
                "    c=np.where(c, \"green\", \"red\"),\n",
                "    s=1.2,\n",
                ")\n",
                "inset_ax.scatter(\n",
                "    feasible_points[-40:, 0],\n",
                "    feasible_points[-40:, 1],\n",
                "    c=np.where(vmec_feasible, \"green\", \"red\"),\n",
                "    marker=\"x\",\n",
                "    s=80,\n",
                "    linewidths=0.7,\n",
                ")\n",
                "inset_ax.scatter(\n",
                "    Z_feasible[:, 0],\n",
                "    Z_feasible[:, 1],\n",
                "    c=\"blue\",\n",
                "    marker=\"+\",\n",
                "    s=40,\n",
                "    linewidths=0.7,\n",
                ")\n",
                "\n",
                "# Set axis limits for the inset. Set the limits based on the data.\n",
                "inset_ax.set_xlim(0.7, 0.8)\n",
                "inset_ax.set_ylim(1.1, 1.3)\n",
                "\n",
                "# Remove axis labels for the inset\n",
                "inset_ax.set_xticks([])\n",
                "inset_ax.set_yticks([])\n",
                "\n",
                "# Add zoom lines connecting the inset to the main plot\n",
                "mark_inset(ax, inset_ax, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\", lw=1)\n",
                "\n",
                "# Add labels, title, and legend\n",
                "ax.set_xlabel(\"PC1\")\n",
                "ax.set_ylabel(\"PC2\")\n",
                "ax.legend(\n",
                "    loc=\"lower right\",  # Move legend to bottom-right\n",
                "    frameon=True,       # Add a bounding box\n",
                "    fontsize=20,        # Adjust font size\n",
                "    fancybox=True,      # Rounded corners for the box\n",
                "    shadow=True         # Add shadow to the box\n",
                ")\n",
                "plt.tight_layout()\n",
                "\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a263e0fa",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
